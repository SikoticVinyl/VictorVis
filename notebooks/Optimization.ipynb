{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Optimization and Refinement\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this notebook, we focus on optimizing and refining the models developed in previous steps. While the initial models provided a good baseline, further fine-tuning is required to improve their performance and ensure they generalize well to new data.\n",
    "\n",
    "### Objectives:\n",
    "- **Hyperparameter Tuning**: We will explore different sets of hyperparameters using methods such as grid search or random search to identify the best configurations for each model.\n",
    "- **Cross-Validation**: To ensure the models are robust and not overfitting, we will use cross-validation to evaluate their performance on multiple data subsets.\n",
    "- **Model Comparison**: After optimization, we will compare the models based on key metrics such as accuracy, precision, recall, F1-score, and more, ensuring we select the best-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "from tabulate import tabulate\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-split data\n",
    "X_train = joblib.load('../outputs/X_train_encoded.joblib')\n",
    "X_test = joblib.load('../outputs/X_test_encoded.joblib')\n",
    "y_train = joblib.load('../outputs/y_train.joblib')\n",
    "y_test = joblib.load('../outputs/y_test.joblib')\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    return mse, r2\n",
    "\n",
    "# Initialize results tracking\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and evaluate baseline models\n",
    "print(\"Loading and evaluating baseline models...\")\n",
    "baseline_models = {\n",
    "    'RandomForest': joblib.load('../models/random_forest_model.joblib'),\n",
    "    'XGBoost': joblib.load('../models/xgboost_model.joblib')\n",
    "}\n",
    "\n",
    "for name, model in baseline_models.items():\n",
    "    train_mse, train_r2 = evaluate_model(model, X_train, y_train)\n",
    "    test_mse, test_r2 = evaluate_model(model, X_test, y_test)\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Iteration': 'Baseline',\n",
    "        'Train MSE': train_mse,\n",
    "        'Train R2': train_r2,\n",
    "        'Test MSE': test_mse,\n",
    "        'Test R2': test_r2\n",
    "    })\n",
    "    print(f\"Baseline {name} - Test MSE: {test_mse:.4f}, Test R2: {test_r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
