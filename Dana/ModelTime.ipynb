{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player_name                                0\n",
      "real_name                                  0\n",
      "team                                       0\n",
      "age                                        0\n",
      "rating                                     0\n",
      "                                          ..\n",
      "utility_damage_per_round                   0\n",
      "utility_kills_per_100_rounds               0\n",
      "utility_flashes_thrown_per_round           0\n",
      "utility_flash_assists_per_round            0\n",
      "utility_time_opponent_flashed_per_round    0\n",
      "Length: 69, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Load and small preprocess of data \n",
    "\n",
    "data_path = '../CleanData/all_players_df.pkl'\n",
    "df = pd.read_pickle(data_path)\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the age column due to error in current data with age (no time to fix will come back to it)\n",
    "df = df.drop('age', axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape after selecting columns: (968, 13)\n"
     ]
    }
   ],
   "source": [
    "# List of columns selected via feature selection\n",
    "columns_to_keep = [\n",
    "    # Numeric features\n",
    "    'kd_ratio', 'firepower_damage_per_round_win', 'kills_per_round',\n",
    "    'firepower_score', 'impact', 'trading_damage_per_kill', 'kast',\n",
    "    'entrying_support_rounds', 'utility_time_opponent_flashed_per_round',\n",
    "    \n",
    "    # Categorical features\n",
    "    'team',\n",
    "    \n",
    "    # Target variable\n",
    "    'rating'\n",
    "]\n",
    "\n",
    "# Keep selected columns plus player_name and real_name (for reference)\n",
    "df = df[columns_to_keep + ['player_name', 'real_name']]\n",
    "print(f\"DataFrame shape after selecting columns: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X = df.drop(['rating', 'player_name', 'real_name'], axis=1)\n",
    "y = df['rating']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save player names for later reference\n",
    "train_names = df.loc[X_train.index, ['player_name', 'real_name']]\n",
    "test_names = df.loc[X_test.index, ['player_name', 'real_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Encoding for 'team'\n",
    "te_team = TargetEncoder(cols=['team'])\n",
    "X_train_encoded = te_team.fit_transform(X_train, y_train)\n",
    "X_test_encoded = te_team.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of encoded training data: (774, 10)\n",
      "Shape of encoded test data: (194, 10)\n",
      "Feature names: ['kd_ratio', 'firepower_damage_per_round_win', 'kills_per_round', 'firepower_score', 'impact', 'trading_damage_per_kill', 'kast', 'entrying_support_rounds', 'utility_time_opponent_flashed_per_round', 'team']\n"
     ]
    }
   ],
   "source": [
    "# List of numeric features\n",
    "numeric_features = [col for col in X_train.columns if col != 'team']\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the numeric features in the training data\n",
    "X_train_encoded[numeric_features] = scaler.fit_transform(X_train_encoded[numeric_features])\n",
    "\n",
    "# Transform the numeric features in the test data\n",
    "X_test_encoded[numeric_features] = scaler.transform(X_test_encoded[numeric_features])\n",
    "\n",
    "print(\"Shape of encoded training data:\", X_train_encoded.shape)\n",
    "print(\"Shape of encoded test data:\", X_test_encoded.shape)\n",
    "print(\"Feature names:\", X_train_encoded.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Time\n",
    "\n",
    "Time to train the models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42, n_estimators=100),\n",
    "    'XGBoost': XGBRegressor(random_state=42, n_estimators=100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "  MSE: 0.0020\n",
      "  MAE: 0.0374\n",
      "  R-squared: 0.8853\n",
      "\n",
      "Random Forest:\n",
      "  MSE: 0.0018\n",
      "  MAE: 0.0314\n",
      "  R-squared: 0.9003\n",
      "\n",
      "XGBoost:\n",
      "  MSE: 0.0021\n",
      "  MAE: 0.0344\n",
      "  R-squared: 0.8804\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_encoded)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {'model': model, 'mse': mse, 'mae': mae, 'r2': r2}\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R-squared: {r2:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Random Forest\n"
     ]
    }
   ],
   "source": [
    "# Identify the best model\n",
    "best_model = max(results, key=lambda x: results[x]['r2'])\n",
    "print(f\"Best model: {best_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the best model\n",
    "best_model_name = best_model\n",
    "best_model_object = results[best_model_name]['model']\n",
    "y_pred = best_model_object.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with predictions and actual values\n",
    "predictions_df = pd.DataFrame({\n",
    "    'player_name': test_names['player_name'],\n",
    "    'real_name': test_names['real_name'],\n",
    "    'team': X_test['team'],\n",
    "    'actual_rating': y_test,\n",
    "    'predicted_rating': y_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most accurate predictions:\n",
      "    player_name           real_name        team  actual_rating  \\\n",
      "876       AdreN  Dauren Kystaubayev     no team       0.333333   \n",
      "923     SEMINTE      Valentin Bodea     no team       0.274510   \n",
      "626      f0rest     Patrik Lindberg     no team       0.568627   \n",
      "76       regali       Iulian Harjău    entropiq       0.666667   \n",
      "450        eraa       Sean Knutsson  cph wolves       0.509804   \n",
      "260      interz    Timofey Yakushin      cloud9       0.352941   \n",
      "892    oskarish  Oskar Stenborowski     no team       0.313725   \n",
      "231        asap      Tyson Paterson     rooster       0.647059   \n",
      "755       tarik         Tarik Celik     no team       0.431373   \n",
      "535    innocent         Paweł Mocek      rebels       0.352941   \n",
      "\n",
      "     predicted_rating  rating_difference  abs_difference  \n",
      "876          0.333137          -0.000196        0.000196  \n",
      "923          0.274314          -0.000196        0.000196  \n",
      "626          0.568039          -0.000588        0.000588  \n",
      "76           0.667255           0.000588        0.000588  \n",
      "450          0.508824          -0.000980        0.000980  \n",
      "260          0.351569          -0.001373        0.001373  \n",
      "892          0.312157          -0.001569        0.001569  \n",
      "231          0.649216           0.002157        0.002157  \n",
      "755          0.429216          -0.002157        0.002157  \n",
      "535          0.355490           0.002549        0.002549  \n",
      "\n",
      "Top 10 least accurate predictions:\n",
      "    player_name                       real_name         team  actual_rating  \\\n",
      "482       notaN                  Anton Pedersen  ima problem       0.333333   \n",
      "722      Oderus                     Chad Miller      no team       0.450980   \n",
      "516       mopoz  Alejandro Fernández-Quejo Cano          koi       0.352941   \n",
      "428     destiny                     Lucas Bullo        solid       0.411765   \n",
      "198       kreaz                Rasmus Johansson        eclot       0.352941   \n",
      "834        zeff                   Min-Seok Park      no team       0.372549   \n",
      "495   reversive                Roberto Themtham          krü       0.313725   \n",
      "570      kinqie                 Semyon Lisitsyn       rush b       0.254902   \n",
      "323        dobu              Gan-Erdene Batbold         atox       0.431373   \n",
      "275       dephh                    Rory Jackson          m80       0.352941   \n",
      "\n",
      "     predicted_rating  rating_difference  abs_difference  \n",
      "482          0.420980           0.087647        0.087647  \n",
      "722          0.362157          -0.088824        0.088824  \n",
      "516          0.443922           0.090980        0.090980  \n",
      "428          0.509216           0.097451        0.097451  \n",
      "198          0.463922           0.110980        0.110980  \n",
      "834          0.489020           0.116471        0.116471  \n",
      "495          0.430588           0.116863        0.116863  \n",
      "570          0.388235           0.133333        0.133333  \n",
      "323          0.568431           0.137059        0.137059  \n",
      "275          0.512353           0.159412        0.159412  \n"
     ]
    }
   ],
   "source": [
    "# Calculate the difference between predicted and actual ratings\n",
    "predictions_df['rating_difference'] = predictions_df['predicted_rating'] - predictions_df['actual_rating']\n",
    "\n",
    "# Sort by the absolute difference to see the best and worst predictions\n",
    "predictions_df['abs_difference'] = abs(predictions_df['rating_difference'])\n",
    "predictions_df_sorted = predictions_df.sort_values('abs_difference')\n",
    "\n",
    "print(\"Top 10 most accurate predictions:\")\n",
    "print(predictions_df_sorted.head(10))\n",
    "\n",
    "print(\"\\nTop 10 least accurate predictions:\")\n",
    "print(predictions_df_sorted.tail(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions are good\n",
    "\n",
    "With some solid predictions and a best and second best model I am going to save the data and models and move on to optimization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
