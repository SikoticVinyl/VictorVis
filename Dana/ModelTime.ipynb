{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Overview and Summary\n",
    "\n",
    "**Objective:**  \n",
    "This notebook explores player rating predictions using various machine learning models, including **Linear Regression**, **Random Forest**, and **XGBoost**. The goal is to evaluate each model's performance and identify the most accurate predictor for future optimization.\n",
    "\n",
    "**Key Steps:**\n",
    "1. **Data Preprocessing:** Cleaned the dataset, handled missing values, and selected relevant features.\n",
    "2. **Model Training:** Trained and evaluated Linear Regression, Random Forest, and XGBoost models.\n",
    "3. **Model Evaluation:** Compared the models using metrics like Mean Squared Error (MSE), Mean Absolute Error (MAE), and R-squared.\n",
    "4. **Predictions Analysis:** Reviewed the top 10 most accurate and least accurate predictions to understand model behavior.\n",
    "\n",
    "**Findings:**\n",
    "- **Random Forest** performed the best with an R-squared of **0.9003** and the lowest MSE and MAE, making it the strongest candidate for further optimization.\n",
    "- **XGBoost** and **Linear Regression** also performed well, but slightly lagged behind Random Forest in terms of prediction accuracy.\n",
    "- The most accurate predictions had an error difference as small as **0.000196**, demonstrating the model's ability to closely match actual ratings.\n",
    "\n",
    "Next steps involve saving the models and predictions for further optimization, with a focus on **Random Forest** and **XGBoost** for hyperparameter tuning and feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Importing Libraries\n",
    "In this step, we import the essential libraries required for data processing, model training, and evaluation. \n",
    "We use:\n",
    "- `pandas` and `numpy` for data manipulation.\n",
    "- `sklearn` libraries for model creation, preprocessing, and evaluation.\n",
    "- `category_encoders` for encoding categorical features.\n",
    "- `xgboost` for training the XGBoost model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Loading and Preprocessing the Data\n",
    "In this step, we load the dataset from a `.pkl` file using `pandas`. We then check for missing values to ensure data integrity.\n",
    "- **File Path:** The data is loaded from `all_players_df.pkl`.\n",
    "- **Action:** Print the missing values in each column to determine data quality.\n",
    "\n",
    "The 'age' column contains errors, so we drop it to avoid model issues.\n",
    "- **Action:** Drop the 'age' column as a quick fix to proceed with model building. (Plan to revisit later for further analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player_name                                0\n",
      "real_name                                  0\n",
      "team                                       0\n",
      "age                                        0\n",
      "rating                                     0\n",
      "                                          ..\n",
      "utility_damage_per_round                   0\n",
      "utility_kills_per_100_rounds               0\n",
      "utility_flashes_thrown_per_round           0\n",
      "utility_flash_assists_per_round            0\n",
      "utility_time_opponent_flashed_per_round    0\n",
      "Length: 69, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Load and small preprocess of data \n",
    "\n",
    "data_path = '../CleanData/all_players_df.pkl'\n",
    "df = pd.read_pickle(data_path)\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the age column due to error in current data with age (no time to fix will come back to it)\n",
    "df = df.drop('age', axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Feature Selection\n",
    "After initial preprocessing, we select the important features for model training.\n",
    "- **Columns Kept:** We retain several columns for model training based on their relevance which was discoverd through our ExploreData notebook.\n",
    "- **Action:** Print the shape of the DataFrame after selecting the required features to verify the subset size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape after selecting columns: (968, 13)\n"
     ]
    }
   ],
   "source": [
    "# List of columns selected via feature selection\n",
    "columns_to_keep = [\n",
    "    # Numeric features\n",
    "    'kd_ratio', 'firepower_damage_per_round_win', 'kills_per_round',\n",
    "    'firepower_score', 'impact', 'trading_damage_per_kill', 'kast',\n",
    "    'entrying_support_rounds', 'utility_time_opponent_flashed_per_round',\n",
    "    \n",
    "    # Categorical features\n",
    "    'team',\n",
    "    \n",
    "    # Target variable\n",
    "    'rating'\n",
    "]\n",
    "\n",
    "# Keep selected columns plus player_name and real_name (for reference)\n",
    "df = df[columns_to_keep + ['player_name', 'real_name']]\n",
    "print(f\"DataFrame shape after selecting columns: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Splitting the Data\n",
    "We split the dataset into training and testing sets for model evaluation using `train_test_split` from `sklearn`.\n",
    "- **Train-Test Split Ratio:** 80% training, 20% testing.\n",
    "- **Action:** Ensure that the data is correctly split for both model training and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X = df.drop(['rating', 'player_name', 'real_name'], axis=1)\n",
    "y = df['rating']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save player names for later reference\n",
    "train_names = df.loc[X_train.index, ['player_name', 'real_name']]\n",
    "test_names = df.loc[X_test.index, ['player_name', 'real_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Encoding for 'team'\n",
    "te_team = TargetEncoder(cols=['team'])\n",
    "X_train_encoded = te_team.fit_transform(X_train, y_train)\n",
    "X_test_encoded = te_team.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of encoded training data: (774, 10)\n",
      "Shape of encoded test data: (194, 10)\n",
      "Feature names: ['kd_ratio', 'firepower_damage_per_round_win', 'kills_per_round', 'firepower_score', 'impact', 'trading_damage_per_kill', 'kast', 'entrying_support_rounds', 'utility_time_opponent_flashed_per_round', 'team']\n"
     ]
    }
   ],
   "source": [
    "# List of numeric features\n",
    "numeric_features = [col for col in X_train.columns if col != 'team']\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the numeric features in the training data\n",
    "X_train_encoded[numeric_features] = scaler.fit_transform(X_train_encoded[numeric_features])\n",
    "\n",
    "# Transform the numeric features in the test data\n",
    "X_test_encoded[numeric_features] = scaler.transform(X_test_encoded[numeric_features])\n",
    "\n",
    "print(\"Shape of encoded training data:\", X_train_encoded.shape)\n",
    "print(\"Shape of encoded test data:\", X_test_encoded.shape)\n",
    "print(\"Feature names:\", X_train_encoded.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Model Training\n",
    "We train multiple models to predict the target variable, including:\n",
    "- **Linear Regression**\n",
    "- **RandomForestRegressor**\n",
    "- **XGBRegressor**\n",
    "- **Action:** Train these models on the training data using the preprocessed features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42, n_estimators=100),\n",
    "    'XGBoost': XGBRegressor(random_state=42, n_estimators=100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "  MSE: 0.0020\n",
      "  MAE: 0.0374\n",
      "  R-squared: 0.8853\n",
      "\n",
      "Random Forest:\n",
      "  MSE: 0.0018\n",
      "  MAE: 0.0314\n",
      "  R-squared: 0.9003\n",
      "\n",
      "XGBoost:\n",
      "  MSE: 0.0021\n",
      "  MAE: 0.0344\n",
      "  R-squared: 0.8804\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_encoded)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {'model': model, 'mse': mse, 'mae': mae, 'r2': r2}\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R-squared: {r2:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Random Forest\n"
     ]
    }
   ],
   "source": [
    "# Identify the best model\n",
    "best_model = max(results, key=lambda x: results[x]['r2'])\n",
    "print(f\"Best model: {best_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "We trained three different models — **Linear Regression**, **Random Forest**, and **XGBoost** — to predict our target variable. The evaluation metrics used to compare model performance are:\n",
    "\n",
    "- **Mean Squared Error (MSE):** Measures the average of the squared differences between actual and predicted values. A lower MSE is better.\n",
    "- **Mean Absolute Error (MAE):** Measures the average of the absolute differences between actual and predicted values. A lower MAE indicates more accurate predictions.\n",
    "- **R-squared (R²):** Represents the proportion of the variance in the dependent variable that is predictable from the independent variables. An R² closer to 1 means better model performance.\n",
    "\n",
    "#### Model Evaluation Results:\n",
    "\n",
    "1. **Linear Regression**  \n",
    "   - **MSE:** 0.0020  \n",
    "   - **MAE:** 0.0374  \n",
    "   - **R-squared:** 0.8853  \n",
    "\n",
    "   **Interpretation:**  \n",
    "   The Linear Regression model performs reasonably well with an R-squared of 0.8853, indicating that it explains about 88.53% of the variance in the target variable. The error metrics, MSE and MAE, are within an acceptable range but are slightly higher compared to the other models.\n",
    "\n",
    "2. **Random Forest**  \n",
    "   - **MSE:** 0.0018  \n",
    "   - **MAE:** 0.0314  \n",
    "   - **R-squared:** 0.9003  \n",
    "\n",
    "   **Interpretation:**  \n",
    "   The Random Forest model performs the best out of the three models, with the lowest MSE (0.0018) and MAE (0.0314), indicating more accurate predictions. The R-squared value of 0.9003 shows that it captures about 90.03% of the variance in the target variable, making it the strongest performer.\n",
    "\n",
    "3. **XGBoost**  \n",
    "   - **MSE:** 0.0021  \n",
    "   - **MAE:** 0.0344  \n",
    "   - **R-squared:** 0.8804  \n",
    "\n",
    "   **Interpretation:**  \n",
    "   The XGBoost model performs similarly to Linear Regression, with an R-squared of 0.8804, slightly lower than Random Forest. While it does not outperform Random Forest, XGBoost remains a strong model with relatively low MSE and MAE values.\n",
    "\n",
    "#### Conclusion:\n",
    "Among the three models, **Random Forest** gives the best performance, having the lowest errors and the highest R-squared value. This indicates that Random Forest is better at capturing the complexity of the data, making it the most accurate predictor in this case. With **XGBoost** coming seond."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Making Predictions\n",
    "Using the best-performing model, make predictions on the test set.\n",
    "- **Predictions Output:** Output the predicted values and compare them with the actual values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the best model\n",
    "best_model_name = best_model\n",
    "best_model_object = results[best_model_name]['model']\n",
    "y_pred = best_model_object.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with predictions and actual values\n",
    "predictions_df = pd.DataFrame({\n",
    "    'player_name': test_names['player_name'],\n",
    "    'real_name': test_names['real_name'],\n",
    "    'team': X_test['team'],\n",
    "    'actual_rating': y_test,\n",
    "    'predicted_rating': y_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most accurate predictions:\n",
      "    player_name           real_name        team  actual_rating  \\\n",
      "876       AdreN  Dauren Kystaubayev     no team       0.333333   \n",
      "923     SEMINTE      Valentin Bodea     no team       0.274510   \n",
      "626      f0rest     Patrik Lindberg     no team       0.568627   \n",
      "76       regali       Iulian Harjău    entropiq       0.666667   \n",
      "450        eraa       Sean Knutsson  cph wolves       0.509804   \n",
      "260      interz    Timofey Yakushin      cloud9       0.352941   \n",
      "892    oskarish  Oskar Stenborowski     no team       0.313725   \n",
      "231        asap      Tyson Paterson     rooster       0.647059   \n",
      "755       tarik         Tarik Celik     no team       0.431373   \n",
      "535    innocent         Paweł Mocek      rebels       0.352941   \n",
      "\n",
      "     predicted_rating  rating_difference  abs_difference  \n",
      "876          0.333137          -0.000196        0.000196  \n",
      "923          0.274314          -0.000196        0.000196  \n",
      "626          0.568039          -0.000588        0.000588  \n",
      "76           0.667255           0.000588        0.000588  \n",
      "450          0.508824          -0.000980        0.000980  \n",
      "260          0.351569          -0.001373        0.001373  \n",
      "892          0.312157          -0.001569        0.001569  \n",
      "231          0.649216           0.002157        0.002157  \n",
      "755          0.429216          -0.002157        0.002157  \n",
      "535          0.355490           0.002549        0.002549  \n",
      "\n",
      "Top 10 least accurate predictions:\n",
      "    player_name                       real_name         team  actual_rating  \\\n",
      "482       notaN                  Anton Pedersen  ima problem       0.333333   \n",
      "722      Oderus                     Chad Miller      no team       0.450980   \n",
      "516       mopoz  Alejandro Fernández-Quejo Cano          koi       0.352941   \n",
      "428     destiny                     Lucas Bullo        solid       0.411765   \n",
      "198       kreaz                Rasmus Johansson        eclot       0.352941   \n",
      "834        zeff                   Min-Seok Park      no team       0.372549   \n",
      "495   reversive                Roberto Themtham          krü       0.313725   \n",
      "570      kinqie                 Semyon Lisitsyn       rush b       0.254902   \n",
      "323        dobu              Gan-Erdene Batbold         atox       0.431373   \n",
      "275       dephh                    Rory Jackson          m80       0.352941   \n",
      "\n",
      "     predicted_rating  rating_difference  abs_difference  \n",
      "482          0.420980           0.087647        0.087647  \n",
      "722          0.362157          -0.088824        0.088824  \n",
      "516          0.443922           0.090980        0.090980  \n",
      "428          0.509216           0.097451        0.097451  \n",
      "198          0.463922           0.110980        0.110980  \n",
      "834          0.489020           0.116471        0.116471  \n",
      "495          0.430588           0.116863        0.116863  \n",
      "570          0.388235           0.133333        0.133333  \n",
      "323          0.568431           0.137059        0.137059  \n",
      "275          0.512353           0.159412        0.159412  \n"
     ]
    }
   ],
   "source": [
    "# Calculate the difference between predicted and actual ratings\n",
    "predictions_df['rating_difference'] = predictions_df['predicted_rating'] - predictions_df['actual_rating']\n",
    "\n",
    "# Sort by the absolute difference to see the best and worst predictions\n",
    "predictions_df['abs_difference'] = abs(predictions_df['rating_difference'])\n",
    "predictions_df_sorted = predictions_df.sort_values('abs_difference')\n",
    "\n",
    "print(\"Top 10 most accurate predictions:\")\n",
    "print(predictions_df_sorted.head(10))\n",
    "\n",
    "print(\"\\nTop 10 least accurate predictions:\")\n",
    "print(predictions_df_sorted.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Outcomes\n",
    "\n",
    "After training and evaluating our models, we generated predictions for the test set. Below is an analysis of the top 10 most accurate predictions based on the absolute difference between the actual and predicted ratings.\n",
    "\n",
    "#### Top 10 Most Accurate Predictions:\n",
    "\n",
    "| player_name | real_name            | team       | actual_rating | predicted_rating | rating_difference | abs_difference |\n",
    "|-------------|----------------------|------------|---------------|------------------|-------------------|----------------|\n",
    "| AdreN       | Dauren Kystaubayev    | no team    | 0.333333      | 0.333137         | -0.000196         | 0.000196       |\n",
    "| SEMINTE     | Valentin Bodea        | no team    | 0.274510      | 0.274314         | -0.000196         | 0.000196       |\n",
    "| f0rest      | Patrik Lindberg       | no team    | 0.568627      | 0.568039         | -0.000588         | 0.000588       |\n",
    "| regali      | Iulian Harjău         | entropiq   | 0.666667      | 0.667255         |  0.000588         | 0.000588       |\n",
    "| eraa        | Sean Knutsson         | cph wolves | 0.509804      | 0.508824         | -0.000980         | 0.000980       |\n",
    "| interz      | Timofey Yakushin      | cloud9     | 0.352941      | 0.351569         | -0.001373         | 0.001373       |\n",
    "| oskarish    | Oskar Stenborowski    | no team    | 0.313725      | 0.312157         | -0.001569         | 0.001569       |\n",
    "| asap        | Tyson Paterson        | rooster    | 0.647059      | 0.649216         |  0.002157         | 0.002157       |\n",
    "| tarik       | Tarik Celik           | no team    | 0.431373      | 0.429216         | -0.002157         | 0.002157       |\n",
    "| innocent    | Paweł Mocek           | rebels     | 0.352941      | 0.355490         |  0.002549         | 0.002549       |\n",
    "\n",
    "#### Key Insights:\n",
    "\n",
    "- **High Accuracy in Predictions:** \n",
    "  The top 10 predictions have extremely low absolute differences between the actual and predicted ratings. The lowest difference is as small as 0.000196, which indicates that the model's predictions are nearly identical to the true ratings. This highlights the model's strong ability to generalize and make accurate predictions for certain players.\n",
    "\n",
    "- **Notable Players and Teams:** \n",
    "  Some well-known players such as **AdreN**, **f0rest**, and **tarik** feature in the top predictions. This suggests that the model performs well in predicting the ratings of experienced or prominent players, possibly due to the availability of consistent data for such individuals.\n",
    "\n",
    "- **Consistency Across Teams:** \n",
    "  The accurate predictions span across various teams, including both established teams like **cloud9** and less formal groups like **rebels**, as well as our solo players denoated under **no team**. This indicates that the model is not biased towards specific teams and can generalize well across different player categories.\n",
    "\n",
    "#### Conclusion:\n",
    "\n",
    "The results demonstrate the model's ability to accurately predict player ratings for a variety of players. The low rating differences show that the model is well-tuned and has captured important patterns in the data. While some predictions are almost perfect, further tuning and optimization may help reduce the error in less accurate predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Saving Models and Preprocessed Data\n",
    "\n",
    "In this step, we will save the preprocessed data, trained models, and other important components necessary for future use. By saving these objects, we ensure that the models and data can be easily reloaded and reused for predictions or further analysis without having to retrain the models or preprocess the data again. This will make the deployment or evaluation of the models more efficient.\n",
    "\n",
    "The following items will be saved:\n",
    "\n",
    "1. **Preprocessed Data**: \n",
    "   - We will save the preprocessed training and test data (`X_train_encoded`, `X_test_encoded`) as well as the target variables (`y_train`, `y_test`) using `joblib`. These can be reloaded to evaluate model performance or for use in additional models.\n",
    "\n",
    "2. **Trained Models**:\n",
    "   - The trained **Random Forest** and **XGBoost** models will be saved. These models can be reloaded later for making predictions or further fine-tuning.\n",
    "\n",
    "3. **Feature Names**:\n",
    "   - We will save the names of the features used in the models, which will help in future interpretation of the model predictions and understanding the input structure.\n",
    "\n",
    "4. **TargetEncoder for 'team'**:\n",
    "   - The `TargetEncoder` used to transform the `team` categorical variable will be saved. This ensures consistency in encoding when new data is used.\n",
    "\n",
    "5. **StandardScaler**:\n",
    "   - The `StandardScaler` used to standardize the data will be saved, ensuring that any new data can be scaled in the same way as the training data.\n",
    "\n",
    "6. **Predictions**:\n",
    "   - The predictions made by the models on the test data will be saved as a CSV file for further analysis or evaluation.\n",
    "\n",
    "By saving these components, we preserve the entire workflow and ensure that the models, data, and transformations can be easily restored and applied in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports for savings located here so the whole notebook does not have to be re-ruun to save. \n",
    "import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the preprocessed data\n",
    "joblib.dump(X_train_encoded, 'X_train_encoded.joblib')\n",
    "joblib.dump(X_test_encoded, 'X_test_encoded.joblib')\n",
    "joblib.dump(y_train, 'y_train.joblib')\n",
    "joblib.dump(y_test, 'y_test.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the Random Forest model\n",
    "joblib.dump(results['Random Forest']['model'], 'random_forest_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the XGBoost model\n",
    "joblib.dump(results['XGBoost']['model'], 'xgboost_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the feature names\n",
    "with open('feature_names.pkl', 'wb') as f:\n",
    "    pickle.dump(X_train_encoded.columns.tolist(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the TargetEncoder for 'team'\n",
    "joblib.dump(te_team, 'team_target_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the StandardScaler\n",
    "joblib.dump(scaler, 'standard_scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions DataFrame\n",
    "predictions_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All necessary data and models have been saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
